# Imports
import re 
from collections import Counter 
import time 
from langdetect import detect 
from transformers import AutoTokenizer, AutoModelForSequenceClassification,pipeline,MarianMTModel, MarianTokenizer
import torch 
import os

def first_uzd():
    print("\nUzdevuma nosacijumi:")
    print("Izveidot programmu, kas nosaka, cik bieÅ¾i katrs vÄrds atkÄrtojas tekstÄ.")
    print("IgnorÄ“t lielos burtus, lai \"kaÄ·is\" un \"KaÄ·is\" tiktu uzskatÄ«ti par vienÄdiem.")
    print("\nIevade:")
    print("\"MÄkoÅ†ainÄ dienÄ kaÄ·is sÄ“dÄ“ja uz palodzes. KaÄ·is domÄja, kÄpÄ“c debesis ir pelÄ“kas. KaÄ·is gribÄ“ja redzÄ“t sauli, bet saule slÄ“pÄs aiz mÄkoÅ†iem.\"")
    time.sleep(5)

    print("\nRezultats:")
    text = "MÄkoÅ†ainÄ dienÄ kaÄ·is sÄ“dÄ“ja uz palodzes. KaÄ·is domÄja, kÄpÄ“c debesis ir pelÄ“kas. KaÄ·is gribÄ“ja redzÄ“t sauli, bet saule slÄ“pÄs aiz mÄkoÅ†iem."
    text_lowercase = text.lower()
    clean_text= re.sub(r'[^\w\s]', '', text_lowercase)
    words = clean_text.split()
    word_counter = Counter(words)

    for vards, skaits in word_counter.items():
        if skaits > 1:
            print(f"{vards}: {skaits}")

def second_uzd():
    print("\nUzdevuma nosacijumi:")
    print("Izveidot programmu, kas nosaka, kurÄ valodÄ ir katrs teksts. Izmanto bibliotÄ“ku vai algoritmu, kas Ä¼auj identificÄ“t valodu.")
    print("\nIevade:")
    print("\"Å odien ir saulaina diena.\"")
    print("\"Today is a sunny day.\"")
    print("\"Ğ¡ĞµĞ³Ğ¾Ğ´Ğ½Ñ ÑĞ¾Ğ»Ğ½ĞµÑ‡Ğ½Ñ‹Ğ¹ Ğ´ĞµĞ½ÑŒ.\"")
    time.sleep(5)

    print("\nRezultats:")
    texts = [
        "Å odien ir saulaina diena.",
        "Today is a sunny day.",  # Detects as so language i dont know why... D:
        "Ğ¡ĞµĞ³Ğ¾Ğ´Ğ½Ñ ÑĞ¾Ğ»Ğ½ĞµÑ‡Ğ½Ñ‹Ğ¹ Ğ´ĞµĞ½ÑŒ."
    ]

    for x in texts:
        lang= detect(x)
        print(f"Teksts: \"{x}\" -> Valoda: {lang}")

def third_uzd():
    print("\nUzdevuma nosacijumi:")
    print("IdentificÄ“t vÄrdu sakritÄ«bu starp abiem tekstiem")
    print("AprÄ“Ä·inat, cik procentuÄli liels ir sakritÄ«bas lÄ«menis.")
    print("\nIevade:")
    print("\"Rudens lapas ir dzeltenas un oranÅ¾as. Lapas klÄj zemi un padara to krÄsainu.\"")
    print("\"KrÄsainas rudens lapas krÄ«t zemÄ“. Lapas ir oranÅ¾as un dzeltenas.\"")
    time.sleep(5)

    print("\nRezultats:")

    text1 = "Rudens lapas ir dzeltenas un oranÅ¾as. Lapas klÄj zemi un padara to krÄsainu."
    text2 = "KrÄsainas rudens lapas krÄ«t zemÄ“. Lapas ir oranÅ¾as un dzeltenas."

    def update_text(text):
        text_lowercase = text.lower()
        clean_text = re.sub(r'[^\w\s]', '', text_lowercase)
        words = clean_text.split()
        return set(words)

    words1 = update_text(text1)
    words2 = update_text(text2)

    common_words = words1 & words2

    unique_words = words1 | words2
    total = len(unique_words)

    percents = (len(common_words) / total) * 100

    print(f"KopÄ«gie vÄrdi: {common_words}")
    print(f"SakritÄ«bas lÄ«menis: {percents:.2f}%")

def forth_uzd():
    print("\nUzdevuma nosacijumi:")
    print("Izveidot programmu, kas nosaka katra teikuma emocionÄlo noskaÅ†ojumu: pozitÄ«vs, negatÄ«vs vai neitrÄls.")
    print("\nIevade:")
    print("\"Å is produkts ir lielisks, esmu Ä¼oti apmierinÄts!\"")
    print("\"Esmu vÄ«lies, produkts neatbilst aprakstam.\"")
    print("\"NeitrÄls produkts, nekas Ä«paÅ¡s.\"")
    time.sleep(5)

    print("\nRezultats:")

    model_name = "cardiffnlp/twitter-xlm-roberta-base-sentiment"  
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name)

    texts_lv = [
        "Å is produkts ir lielisks, esmu Ä¼oti apmierinÄts!",
        "Esmu vÄ«lies, produkts neatbilst aprakstam.",
        "NeitrÄls produkts, nekas Ä«paÅ¡s."
    ]


    for text in texts_lv:
        inputs = tokenizer(text, return_tensors="pt",  truncation=True, max_length=128)
        outputs = model(**inputs)
        probs = torch.nn.functional.softmax(outputs.logits, dim=1)
        sentiment = torch.argmax(probs).item()

        if sentiment == 0:
            label = "negatÄ«vs"
        elif sentiment == 1:
            label = "neitrÄls"
        else:
            label = "pozitÄ«vs"

        print(f"Teikums: \"{text}\" -> NoskaÅ†ojums: {label}")

def fifth_uzd():
    print("\nUzdevuma nosacijumi:")
    print("NoÅ†em liekos simbolus (piemÄ“ram, @, #, !!!, URL).")
    print("PÄrveido tekstu uz mazajiem burtiem.")
    print("Izveidot tÄ«ru un viegli lasÄmu tekstu.")
    print("\nIevade:")
    print("\"@John: Å is ir lielisks produkts!!! Vai ne? ğŸ‘ğŸ‘ğŸ‘ http://example.com\"")
   
    time.sleep(5)

    print("\nRezultats:")
    txt = "@John: Å is ir lielisks produkts!!! Vai ne? ğŸ‘ğŸ‘ğŸ‘ http://example.com"

    txt = re.sub(r'@\w+', '', txt)  
    txt = re.sub(r'http\S+', '', txt)  
    txt = re.sub(r'[^\w\s.,!?]', '', txt)  
    txt = re.sub(r'\s+', ' ', txt) 
    txt = txt.strip()  

    txt = txt.lower()

    print(txt)

def sixth_uzd():
    print("\nUzdevuma nosacijumi:")
    print("Izveidot programmu, kas automÄtiski rezumÄ“ rakstu un izceÄ¼ galvenÄs idejas.")
    print("\nIevade:")
    print("\"Latvija ir valsts Baltijas reÄ£ionÄ. TÄs galvaspilsÄ“ta ir RÄ«ga, kas ir slavena ar savu vÄ“sturisko centru un skaistajÄm Ä“kÄm. Latvija robeÅ¾ojas ar Lietuvu, Igauniju un Krieviju, kÄ arÄ« tai ir piekÄ¼uve Baltijas jÅ«rai. TÄ ir viena no Eiropas SavienÄ«bas dalÄ«bvalstÄ«m.\"")
    time.sleep(5)
    print("\nRezultats:")

    summarizer = pipeline("summarization", model="Falconsai/text_summarization") # modelis neatbalsta Lv valodu,lÄ«dz ar to tas nekorekti strÄda
    teksts = """Latvija ir valsts Baltijas reÄ£ionÄ. TÄs galvaspilsÄ“ta ir RÄ«ga, kas ir slavena ar savu vÄ“sturisko centru un skaistajÄm Ä“kÄm. Latvija robeÅ¾ojas ar Lietuvu, Igauniju un Krieviju, kÄ arÄ« tai ir piekÄ¼uve Baltijas jÅ«rai. TÄ ir viena no Eiropas SavienÄ«bas dalÄ«bvalstÄ«m."""
    print(summarizer(teksts, max_length=1000, min_length=30, do_sample=False)) # output [{'summary_text': 'Latvija robeojas ar Lietuvu, Igauniju un Krieviju, k ar tai ir piekuve Baltijas jrai.'}]

def seventh_uzd(): # Nav gatavs
    print("\nUzdevuma nosacijumi:")
    print("Izmanto vÄrdu iegulÅ¡anas modeli, lai:")
    print("1.IegÅ«tu katra vÄrda vektoru.")
    print("2.SalÄ«dzinÄtu, kuri vÄrdi ir semantiski lÄ«dzÄ«gÄki.")
    print("\nIevade:")
    print("VÄrdi: mÄja ; dzÄ«voklis ; jÅ«ra")
    time.sleep(5)
    print("\nRezultats:")
    
def eight_uzd():


    ner_pipeline = pipeline(
        "ner",
        model="Davlan/bert-base-multilingual-cased-ner-hrl",
        tokenizer="Davlan/bert-base-multilingual-cased-ner-hrl",
        grouped_entities=True
    )

    
    text = "Valsts prezidents Egils Levits piedalÄ«jÄs pasÄkumÄ, ko organizÄ“ja Latvijas UniversitÄte."

    
    entities = ner_pipeline(text)

    for entity in entities:
        if entity['entity_group'] in ['PER', 'ORG']:
            print(f"{entity['word']}: {entity['entity_group']}")

def nineth_uzd(): # Nav gatavs
    print()

def ten_uzd():
    modelis_nosaukums = 'Helsinki-NLP/opus-mt-lv-en'
    tokenizer = MarianTokenizer.from_pretrained(modelis_nosaukums)
    model = MarianMTModel.from_pretrained(modelis_nosaukums)

    teksti = [
        "Labdien! KÄ jums klÄjas?",
        "Es Å¡odien lasÄ«ju interesantu grÄmatu."
    ]

    for teksts in teksti:
        tokens = tokenizer.prepare_seq2seq_batch([teksts], return_tensors='pt')
        tulkojums = model.generate(**tokens)
        tulkots_teksts = tokenizer.decode(tulkojums[0], skip_special_tokens=True)
        print(f"Latviski: \"{teksts}\" -> Angliski: \"{tulkots_teksts}\"")



while True:
    try:
        # Main console
        print("\nIzvÄ“lieties vienu no uzdevumiem")
        print("Uzdevums 1: VÄrdu bieÅ¾uma analÄ«ze tekstÄ")
        print("Uzdevums 2: Teksta valodas noteikÅ¡ana")
        print("Uzdevums 3: VÄrdu sakritÄ«bu pÄrbaude divos tekstos")
        print("Uzdevums 4: NoskaÅ†ojuma analÄ«ze")
        print("Uzdevums 5: Teksta tÄ«rÄ«Å¡ana un normalizÄ“Å¡ana")
        print("Uzdevums 6: AutomÄtiska rezumÄ“Å¡ana - strÄda,bet ne tÄ kÄ vajag")
        print("Uzdevums 7: VÄrdu iegulÅ¡ana (word embeddings) - Nav gatavs")
        print("Uzdevums 8: FrÄÅ¾u atpazÄ«Å¡ana (NER) ")
        print("Uzdevums 9: Teksta Ä£enerÄ“Å¡ana - Nav gatavs")
        print("Uzdevums 10: TulkotÄja izveide")
        print("11 izslegt programmu")
        uzd = int(input("JÅ«su izvele: "))


        if uzd == 1:
            first_uzd()
        elif uzd == 2:
            second_uzd()
        elif uzd == 3:
            third_uzd()
        elif uzd == 4:
            forth_uzd()
        elif uzd == 5:
            fifth_uzd()
        elif uzd == 6:
            sixth_uzd()
        elif uzd == 7:
            seventh_uzd()
        elif uzd == 8:
            eight_uzd()
        elif uzd == 9:
            nineth_uzd()
        elif uzd == 10:
            ten_uzd()
        elif uzd == 11:
            break
    except:
        print("\n\n\nIevadiet ciparu!")